{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "631d03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试EfficientNet\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable, Function\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "\n",
    "from src.models.EfficientNet import EfficientNet as EffNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ae3ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet_decoder\n",
    "\n",
    "def EfficientNet(pretrained=False, **kwargs):\n",
    "    model = Efficient_decoder(num_class=4, phi=0, load_weights=True)\n",
    "    return model\n",
    "\n",
    "class upsample(nn.Module):\n",
    "\n",
    "    def __init__(self, if_deconv=True, channels=None):\n",
    "        super(upsample, self).__init__()\n",
    "        if if_deconv:\n",
    "            self.upsample = nn.ConvTranspose2d(channels, channels, 4, stride=2, padding=1, bias=False)\n",
    "        else:\n",
    "            self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        return x\n",
    "\n",
    "class change_channel(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(change_channel, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class Efficient_decoder(nn.Module):\n",
    "    def __init__(self, num_class, phi=0, load_weights=False):\n",
    "        super(Efficient_decoder, self).__init__()\n",
    "        self.backbone = EffNet.from_pretrained(f'efficientnet-b{phi}', load_weights)\n",
    "        #self.ratio_convert = nn.Conv2d(in_channels=1280, out_channels=640, kernel_size=(1,4), stride=(1,2), padding=(0,1))\n",
    "        #self.ratio_convert = nn.Conv2d(in_channels=320, out_channels=640, kernel_size=(1,4), stride=(1,2), padding=(0,1))\n",
    "        \n",
    "        self.up1 = upsample(if_deconv=True, channels=320)  #恢复图像大小,8->16\n",
    "        self.change_channel1 = change_channel(320, 256)\n",
    "        self.up2 = upsample(if_deconv=True, channels=256)  #恢复图像大小,16->32\n",
    "        self.change_channel2 = change_channel(256, 128)\n",
    "        self.up3 = upsample(if_deconv=True, channels=128)  #恢复图像大小,32->64\n",
    "        self.change_channel3 = change_channel(128, 64)\n",
    "        self.conv_out_1 = nn.Conv2d(64, num_class, 3, padding=1)\n",
    "        self.conv_out_2 = nn.Conv2d(64, num_class, 3, padding=1)\n",
    "\n",
    "    def decoder(self, x):\n",
    "        x = self.up1(x)   #([N, 640, 16, 16])\n",
    "        x = self.change_channel1(x)   #([N, 256, 16, 16])\n",
    "        \n",
    "        x = self.up2(x)   #([N, 256, 32, 32])\n",
    "        x = self.change_channel2(x)   #([N, 128, 32, 32])\n",
    "        \n",
    "        x = self.up3(x)   #([N, 128, 64, 64])\n",
    "        x = self.change_channel3(x)   #([N, 64, 64, 64])\n",
    "        \n",
    "        x1 = self.conv_out_1(x)\n",
    "        x2 = self.conv_out_2(x)\n",
    "        return x1, x2\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.extract_features(x)  # 输出维度（N，1280, H/32, W/32），其中H，W为原图像的高和宽，实验中输入原图像的尺寸为（256, 512），输出（8,16）（\n",
    "        print(\"x.shape after backbone extract_features: \", x.shape)\n",
    "        #x = self.ratio_convert(x)   #输出维度（N，640, H/32, W/64） 高和宽比例1：1,实验中得到（N，640,8,8）\n",
    "        out1, out2 = self.decoder(x)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fa27eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 9, 451, 801] to have 3 channels, but got 9 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m450\u001b[39m,\u001b[38;5;241m800\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m EfficientNet()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/dataset/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mEfficient_decoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 69\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 输出维度（N，1280, H/32, W/32），其中H，W为原图像的高和宽，实验中输入原图像的尺寸为（256, 512），输出（8,16）（\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx.shape after backbone extract_features: \u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m#x = self.ratio_convert(x)   #输出维度（N，640, H/32, W/64） 高和宽比例1：1,实验中得到（N，640,8,8）\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/0_code/img_squence/img_squence_code/src/models/EfficientNet.py:512\u001b[0m, in \u001b[0;36mEfficientNet.extract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03m\"\"\" Returns output of the final convolution layer \"\"\"\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;66;03m# Stem\u001b[39;00m\n\u001b[0;32m--> 512\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swish(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bn0(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_stem\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    514\u001b[0m \u001b[38;5;66;03m# Blocks\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocks):\n",
      "File \u001b[0;32m~/miniconda3/envs/dataset/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/workspace/0_code/img_squence/img_squence_code/src/models/EfficientNet.py:140\u001b[0m, in \u001b[0;36mConv2dStaticSamePadding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    139\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_padding(x)\n\u001b[0;32m--> 140\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 3, 3, 3], expected input[1, 9, 451, 801] to have 3 channels, but got 9 channels instead"
     ]
    }
   ],
   "source": [
    "# 随机input测试\n",
    "device = torch.device(\"cuda:0\")\n",
    "input_tensor = torch.randn(1,9,450,800).to(device)\n",
    "model = EfficientNet().to(device)\n",
    "output = model(input_tensor)\n",
    "print(output[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a68c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入nuscenes图像测试\n",
    "from argparse import ArgumentParser\n",
    "from src.data.data_factory import build_dataloaders\n",
    "from src.utils.configs import get_default_configuration\n",
    "from src.data.utils import create_visual_anno\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load the configuration for this experiment\n",
    "def get_configuration(args):\n",
    "\n",
    "    # Load config defaults\n",
    "    config = get_default_configuration()\n",
    "\n",
    "    # Load dataset options\n",
    "    config.merge_from_file(f'configs/datasets/{args.dataset}.yml')\n",
    "\n",
    "\n",
    "    # Restore config from an existing experiment\n",
    "    if args.resume is not None:\n",
    "        config.merge_from_file(os.path.join(args.resume, 'config.yml'))\n",
    "    \n",
    "    # Override with command line options\n",
    "    config.merge_from_list(args.options)\n",
    "\n",
    "    # Finalise config\n",
    "    config.freeze()\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59181c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument('--tag', type=str, default='run',\n",
    "                    help='optional tag to identify the run')\n",
    "parser.add_argument('--dataset', choices=['nuscenes', 'argoverse'],\n",
    "                    default='nuscenes', help='dataset to train on')\n",
    "parser.add_argument('--model', choices=['pyramid', 'vpn', 'ved'],\n",
    "                    default='pyramid', help='model to train')\n",
    "parser.add_argument('--experiment', default='test', \n",
    "                    help='name of experiment config to load')\n",
    "parser.add_argument('--resume', default=None, \n",
    "                    help='path to an experiment to resume')\n",
    "parser.add_argument('--options', nargs='*', default=[],\n",
    "                    help='list of addition config options as key-val pairs')\n",
    "args = parser.parse_args(args=['--tag', 'run',  '--dataset', 'nuscenes', '--model', 'pyramid',\n",
    "                               '--experiment', 'test'])\n",
    "\n",
    "# Load configuration\n",
    "config = get_configuration(args)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = build_dataloaders(config.train_dataset, config)\n",
    "train_data = next(iter(train_loader))\n",
    "img_sequence = train_data[0]\n",
    "labels = train_data[2]\n",
    "name_sequence = train_data[3]\n",
    "\n",
    "img_1 = img_sequence[0][0]\n",
    "img_2 = img_sequence[1][0]\n",
    "img_3 = img_sequence[2][0]  #(3,450,800)\n",
    "print(\"img shape: \", img_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afeac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = torch.from_numpy(img_1)\n",
    "input_img = torch.unsqueeze(img_1, 0).to(device)\n",
    "print(input_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7108732",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(input_img)\n",
    "print(out[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8794061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00e99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07f9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(name=\"GS\", job='worker', hard=True):\n",
    "    print(\"name is {}, his job is {}, is his job hard? {}\".format(name, job, hard))\n",
    "    \n",
    "test('WMH', hard=False)\n",
    "test('WMH', False)\n",
    "test(\"WMH\",,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12798f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[100,  50],\n",
       "        [200, 300],\n",
       "        [ 70, 200],\n",
       "        [ 50, 100]], dtype=int32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts = np.array([[100,50],[200,300],[70,200],[50,100]],np.int32)\n",
    "[pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32ea5f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  1 100]]\n",
      "\n",
      " [[100 100]]\n",
      "\n",
      " [[100   1]]\n",
      "\n",
      " [[  1   1]]]\n"
     ]
    }
   ],
   "source": [
    "init_pts = [(1,100),(100,100),(100,1),(1,1)]\n",
    "pts = np.array(init_pts, np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "print(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accf9e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = np.array([[231,56],[1061,69],[1066,611],[217,602]], np.int32)\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6f650a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([231.,  56.,   1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pt = (231, 56)\n",
    "pt = np.array(test_pt, np.float32)\n",
    "a = np.append(pt, 1)\n",
    "print(type(test_pt))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a8035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21251656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123909a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试train val test划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "678a67e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.nuscenes.splits import TRAIN_SCENES, VAL_SCENES, CALIBRATION_SCENES\n",
    "#print(VAL_SCENES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fb6834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_SCENES 689个 VAL_SCENES 148个，TEST_SCENES 150个  CALIBRATION_SCENES 50个\n",
    "TEST_SCENES = \\\n",
    "    ['scene-0077', 'scene-0078', 'scene-0079', 'scene-0080', 'scene-0081', 'scene-0082', 'scene-0083', 'scene-0084',\n",
    "     'scene-0085', 'scene-0086', 'scene-0087', 'scene-0088', 'scene-0089', 'scene-0090', 'scene-0091', 'scene-0111',\n",
    "     'scene-0112', 'scene-0113', 'scene-0114', 'scene-0115', 'scene-0116', 'scene-0117', 'scene-0118', 'scene-0119',\n",
    "     'scene-0140', 'scene-0142', 'scene-0143', 'scene-0144', 'scene-0145', 'scene-0146', 'scene-0147', 'scene-0148',\n",
    "     'scene-0265', 'scene-0266', 'scene-0279', 'scene-0280', 'scene-0281', 'scene-0282', 'scene-0307', 'scene-0308',\n",
    "     'scene-0309', 'scene-0310', 'scene-0311', 'scene-0312', 'scene-0313', 'scene-0314', 'scene-0333', 'scene-0334',\n",
    "     'scene-0335', 'scene-0336', 'scene-0337', 'scene-0338', 'scene-0339', 'scene-0340', 'scene-0341', 'scene-0342',\n",
    "     'scene-0343', 'scene-0481', 'scene-0482', 'scene-0483', 'scene-0484', 'scene-0485', 'scene-0486', 'scene-0487',\n",
    "     'scene-0488', 'scene-0489', 'scene-0490', 'scene-0491', 'scene-0492', 'scene-0493', 'scene-0494', 'scene-0495',\n",
    "     'scene-0496', 'scene-0497', 'scene-0498', 'scene-0547', 'scene-0548', 'scene-0549', 'scene-0550', 'scene-0551',\n",
    "     'scene-0601', 'scene-0602', 'scene-0603', 'scene-0604', 'scene-0606', 'scene-0607', 'scene-0608', 'scene-0609',\n",
    "     'scene-0610', 'scene-0611', 'scene-0612', 'scene-0613', 'scene-0614', 'scene-0615', 'scene-0616', 'scene-0617',\n",
    "     'scene-0618', 'scene-0619', 'scene-0620', 'scene-0621', 'scene-0622', 'scene-0623', 'scene-0624', 'scene-0827',\n",
    "     'scene-0828', 'scene-0829', 'scene-0830', 'scene-0831', 'scene-0833', 'scene-0834', 'scene-0835', 'scene-0836',\n",
    "     'scene-0837', 'scene-0838', 'scene-0839', 'scene-0840', 'scene-0841', 'scene-0842', 'scene-0844', 'scene-0845',\n",
    "     'scene-0846', 'scene-0932', 'scene-0933', 'scene-0935', 'scene-0936', 'scene-0937', 'scene-0938', 'scene-0939',\n",
    "     'scene-0940', 'scene-0941', 'scene-0942', 'scene-0943', 'scene-1026', 'scene-1027', 'scene-1028', 'scene-1029',\n",
    "     'scene-1030', 'scene-1031', 'scene-1032', 'scene-1033', 'scene-1034', 'scene-1035', 'scene-1036', 'scene-1037',\n",
    "     'scene-1038', 'scene-1039', 'scene-1040', 'scene-1041', 'scene-1042', 'scene-1043']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16ec125e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求TRAIN_SCENES和TEST_SCENES的交集\n",
    "\n",
    "#set(TRAIN_SCENES).intersection(set(TEST_SCENES))\n",
    "len(set(VAL_SCENES).intersection(set(TEST_SCENES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e9666a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "NEW_VAL = sample(TRAIN_SCENES, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ade1a0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scene-0559', 'scene-0446', 'scene-0193', 'scene-0457', 'scene-0813', 'scene-0183', 'scene-0453', 'scene-0561', 'scene-0354', 'scene-0585', 'scene-0635', 'scene-0922', 'scene-0134', 'scene-0328', 'scene-1054', 'scene-0108', 'scene-0653', 'scene-1025', 'scene-1084', 'scene-1088', 'scene-0479', 'scene-0662', 'scene-0288', 'scene-0886', 'scene-0872', 'scene-0661', 'scene-0057', 'scene-1020', 'scene-0095', 'scene-0784', 'scene-0402', 'scene-0381', 'scene-0594', 'scene-1052', 'scene-1044', 'scene-0331', 'scene-0240', 'scene-0360', 'scene-0808', 'scene-0903', 'scene-0926', 'scene-0171', 'scene-0173', 'scene-0128', 'scene-0228', 'scene-0781', 'scene-1079', 'scene-0162', 'scene-0819', 'scene-0992', 'scene-0921', 'scene-0806', 'scene-0877', 'scene-0792', 'scene-0304', 'scene-0423', 'scene-0318', 'scene-0427', 'scene-0222', 'scene-0880', 'scene-0172', 'scene-0627', 'scene-0659', 'scene-0094', 'scene-0502', 'scene-0251', 'scene-0023', 'scene-0125', 'scene-0524', 'scene-0295', 'scene-1045', 'scene-0401', 'scene-0074', 'scene-0030', 'scene-0220', 'scene-0521', 'scene-0977', 'scene-0820', 'scene-0923', 'scene-1098', 'scene-0440', 'scene-0064', 'scene-0679', 'scene-0656', 'scene-0102', 'scene-0210', 'scene-0364', 'scene-0257', 'scene-0044', 'scene-0174', 'scene-0584', 'scene-0930', 'scene-0668', 'scene-0504', 'scene-0058', 'scene-0129', 'scene-0170', 'scene-1006', 'scene-0705', 'scene-0429', 'scene-0816', 'scene-0634', 'scene-0249', 'scene-1067', 'scene-0349', 'scene-0432', 'scene-0061', 'scene-0103', 'scene-0290', 'scene-0291', 'scene-0062', 'scene-1085', 'scene-0185', 'scene-0436', 'scene-1048', 'scene-0449', 'scene-0120', 'scene-0861', 'scene-0452', 'scene-0712', 'scene-0499', 'scene-1071', 'scene-1072', 'scene-0736', 'scene-1102', 'scene-0991', 'scene-0177', 'scene-0254', 'scene-0005', 'scene-0219', 'scene-0996', 'scene-0695', 'scene-0211', 'scene-0629', 'scene-0509', 'scene-0980', 'scene-0998', 'scene-0655', 'scene-0388', 'scene-0821', 'scene-0786', 'scene-0226', 'scene-0706', 'scene-0296', 'scene-0961', 'scene-0297', 'scene-0626', 'scene-0847', 'scene-0373', 'scene-1077']\n"
     ]
    }
   ],
   "source": [
    "print(NEW_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0604511",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['scene-0559', 'scene-0446', 'scene-0193', 'scene-0457', 'scene-0813', 'scene-0183', 'scene-0453', 'scene-0561', 'scene-0354', 'scene-0585', 'scene-0635', 'scene-0922', 'scene-0134', 'scene-0328', 'scene-1054', 'scene-0108', 'scene-0653', 'scene-1025', 'scene-1084', 'scene-1088', 'scene-0479', 'scene-0662', 'scene-0288', 'scene-0886', 'scene-0872', 'scene-0661', 'scene-0057', 'scene-1020', 'scene-0095', 'scene-0784', 'scene-0402', 'scene-0381', 'scene-0594', 'scene-1052', 'scene-1044', 'scene-0331', 'scene-0240', 'scene-0360', 'scene-0808', 'scene-0903', 'scene-0926', 'scene-0171', 'scene-0173', 'scene-0128', 'scene-0228', 'scene-0781', 'scene-1079', 'scene-0162', 'scene-0819', 'scene-0992', 'scene-0921', 'scene-0806', 'scene-0877', 'scene-0792', 'scene-0304', 'scene-0423', 'scene-0318', 'scene-0427', 'scene-0222', 'scene-0880', 'scene-0172', 'scene-0627', 'scene-0659', 'scene-0094', 'scene-0502', 'scene-0251', 'scene-0023', 'scene-0125', 'scene-0524', 'scene-0295', 'scene-1045', 'scene-0401', 'scene-0074', 'scene-0030', 'scene-0220', 'scene-0521', 'scene-0977', 'scene-0820', 'scene-0923', 'scene-1098', 'scene-0440', 'scene-0064', 'scene-0679', 'scene-0656', 'scene-0102', 'scene-0210', 'scene-0364', 'scene-0257', 'scene-0044', 'scene-0174', 'scene-0584', 'scene-0930', 'scene-0668', 'scene-0504', 'scene-0058', 'scene-0129', 'scene-0170', 'scene-1006', 'scene-0705', 'scene-0429', 'scene-0816', 'scene-0634', 'scene-0249', 'scene-1067', 'scene-0349', 'scene-0432', 'scene-0061', 'scene-0103', 'scene-0290', 'scene-0291', 'scene-0062', 'scene-1085', 'scene-0185', 'scene-0436', 'scene-1048', 'scene-0449', 'scene-0120', 'scene-0861', 'scene-0452', 'scene-0712', 'scene-0499', 'scene-1071', 'scene-1072', 'scene-0736', 'scene-1102', 'scene-0991', 'scene-0177', 'scene-0254', 'scene-0005', 'scene-0219', 'scene-0996', 'scene-0695', 'scene-0211', 'scene-0629', 'scene-0509', 'scene-0980', 'scene-0998', 'scene-0655', 'scene-0388', 'scene-0821', 'scene-0786', 'scene-0226', 'scene-0706', 'scene-0296', 'scene-0961', 'scene-0297', 'scene-0626', 'scene-0847', 'scene-0373', 'scene-1077']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7aca33d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scene-0005', 'scene-0023', 'scene-0030', 'scene-0044', 'scene-0057', 'scene-0058', 'scene-0061', 'scene-0062', 'scene-0064', 'scene-0074', 'scene-0094', 'scene-0095', 'scene-0102', 'scene-0103', 'scene-0108', 'scene-0120', 'scene-0125', 'scene-0128', 'scene-0129', 'scene-0134', 'scene-0162', 'scene-0170', 'scene-0171', 'scene-0172', 'scene-0173', 'scene-0174', 'scene-0177', 'scene-0183', 'scene-0185', 'scene-0193', 'scene-0210', 'scene-0211', 'scene-0219', 'scene-0220', 'scene-0222', 'scene-0226', 'scene-0228', 'scene-0240', 'scene-0249', 'scene-0251', 'scene-0254', 'scene-0257', 'scene-0288', 'scene-0290', 'scene-0291', 'scene-0295', 'scene-0296', 'scene-0297', 'scene-0304', 'scene-0318', 'scene-0328', 'scene-0331', 'scene-0349', 'scene-0354', 'scene-0360', 'scene-0364', 'scene-0373', 'scene-0381', 'scene-0388', 'scene-0401', 'scene-0402', 'scene-0423', 'scene-0427', 'scene-0429', 'scene-0432', 'scene-0436', 'scene-0440', 'scene-0446', 'scene-0449', 'scene-0452', 'scene-0453', 'scene-0457', 'scene-0479', 'scene-0499', 'scene-0502', 'scene-0504', 'scene-0509', 'scene-0521', 'scene-0524', 'scene-0559', 'scene-0561', 'scene-0584', 'scene-0585', 'scene-0594', 'scene-0626', 'scene-0627', 'scene-0629', 'scene-0634', 'scene-0635', 'scene-0653', 'scene-0655', 'scene-0656', 'scene-0659', 'scene-0661', 'scene-0662', 'scene-0668', 'scene-0679', 'scene-0695', 'scene-0705', 'scene-0706', 'scene-0712', 'scene-0736', 'scene-0781', 'scene-0784', 'scene-0786', 'scene-0792', 'scene-0806', 'scene-0808', 'scene-0813', 'scene-0816', 'scene-0819', 'scene-0820', 'scene-0821', 'scene-0847', 'scene-0861', 'scene-0872', 'scene-0877', 'scene-0880', 'scene-0886', 'scene-0903', 'scene-0921', 'scene-0922', 'scene-0923', 'scene-0926', 'scene-0930', 'scene-0961', 'scene-0977', 'scene-0980', 'scene-0991', 'scene-0992', 'scene-0996', 'scene-0998', 'scene-1006', 'scene-1020', 'scene-1025', 'scene-1044', 'scene-1045', 'scene-1048', 'scene-1052', 'scene-1054', 'scene-1067', 'scene-1071', 'scene-1072', 'scene-1077', 'scene-1079', 'scene-1084', 'scene-1085', 'scene-1088', 'scene-1098', 'scene-1102']\n"
     ]
    }
   ],
   "source": [
    "a.sort()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33527ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "train_set = TRAIN_SCENES\n",
    "print(len(train_set))\n",
    "train_new = list(set(train_set).difference(set(a)))\n",
    "train_new.sort()\n",
    "print(type(train_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e16d93fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scene-0002', 'scene-0003', 'scene-0004', 'scene-0006', 'scene-0007', 'scene-0008', 'scene-0009', 'scene-0012', 'scene-0013', 'scene-0014', 'scene-0015', 'scene-0016', 'scene-0017', 'scene-0018', 'scene-0019', 'scene-0021', 'scene-0022', 'scene-0024', 'scene-0025', 'scene-0026', 'scene-0027', 'scene-0028', 'scene-0029', 'scene-0031', 'scene-0032', 'scene-0033', 'scene-0034', 'scene-0035', 'scene-0036', 'scene-0039', 'scene-0042', 'scene-0043', 'scene-0045', 'scene-0046', 'scene-0047', 'scene-0048', 'scene-0049', 'scene-0050', 'scene-0051', 'scene-0052', 'scene-0055', 'scene-0056', 'scene-0059', 'scene-0060', 'scene-0063', 'scene-0065', 'scene-0066', 'scene-0067', 'scene-0068', 'scene-0069', 'scene-0070', 'scene-0071', 'scene-0072', 'scene-0073', 'scene-0075', 'scene-0076', 'scene-0092', 'scene-0093', 'scene-0096', 'scene-0097', 'scene-0098', 'scene-0099', 'scene-0100', 'scene-0101', 'scene-0104', 'scene-0105', 'scene-0106', 'scene-0107', 'scene-0109', 'scene-0110', 'scene-0123', 'scene-0124', 'scene-0126', 'scene-0127', 'scene-0130', 'scene-0131', 'scene-0132', 'scene-0133', 'scene-0135', 'scene-0138', 'scene-0149', 'scene-0150', 'scene-0151', 'scene-0154', 'scene-0155', 'scene-0157', 'scene-0158', 'scene-0159', 'scene-0161', 'scene-0163', 'scene-0164', 'scene-0165', 'scene-0166', 'scene-0167', 'scene-0168', 'scene-0175', 'scene-0176', 'scene-0178', 'scene-0179', 'scene-0180', 'scene-0181', 'scene-0182', 'scene-0187', 'scene-0188', 'scene-0190', 'scene-0191', 'scene-0192', 'scene-0194', 'scene-0195', 'scene-0196', 'scene-0199', 'scene-0200', 'scene-0202', 'scene-0203', 'scene-0204', 'scene-0206', 'scene-0207', 'scene-0208', 'scene-0209', 'scene-0212', 'scene-0213', 'scene-0214', 'scene-0218', 'scene-0221', 'scene-0224', 'scene-0225', 'scene-0227', 'scene-0229', 'scene-0230', 'scene-0231', 'scene-0232', 'scene-0233', 'scene-0234', 'scene-0235', 'scene-0236', 'scene-0237', 'scene-0238', 'scene-0239', 'scene-0241', 'scene-0242', 'scene-0243', 'scene-0244', 'scene-0245', 'scene-0246', 'scene-0247', 'scene-0248', 'scene-0250', 'scene-0252', 'scene-0253', 'scene-0255', 'scene-0256', 'scene-0258', 'scene-0259', 'scene-0260', 'scene-0261', 'scene-0262', 'scene-0263', 'scene-0264', 'scene-0268', 'scene-0270', 'scene-0271', 'scene-0272', 'scene-0273', 'scene-0274', 'scene-0275', 'scene-0276', 'scene-0277', 'scene-0278', 'scene-0283', 'scene-0284', 'scene-0285', 'scene-0286', 'scene-0287', 'scene-0289', 'scene-0292', 'scene-0293', 'scene-0294', 'scene-0298', 'scene-0299', 'scene-0300', 'scene-0301', 'scene-0302', 'scene-0303', 'scene-0305', 'scene-0306', 'scene-0315', 'scene-0316', 'scene-0317', 'scene-0321', 'scene-0323', 'scene-0324', 'scene-0329', 'scene-0330', 'scene-0332', 'scene-0344', 'scene-0345', 'scene-0346', 'scene-0350', 'scene-0351', 'scene-0352', 'scene-0353', 'scene-0355', 'scene-0356', 'scene-0357', 'scene-0358', 'scene-0359', 'scene-0361', 'scene-0362', 'scene-0363', 'scene-0365', 'scene-0367', 'scene-0370', 'scene-0371', 'scene-0372', 'scene-0374', 'scene-0375', 'scene-0376', 'scene-0377', 'scene-0379', 'scene-0380', 'scene-0382', 'scene-0383', 'scene-0384', 'scene-0385', 'scene-0386', 'scene-0399', 'scene-0400', 'scene-0403', 'scene-0405', 'scene-0406', 'scene-0407', 'scene-0408', 'scene-0420', 'scene-0421', 'scene-0422', 'scene-0424', 'scene-0425', 'scene-0426', 'scene-0428', 'scene-0430', 'scene-0431', 'scene-0433', 'scene-0434', 'scene-0435', 'scene-0437', 'scene-0438', 'scene-0439', 'scene-0441', 'scene-0442', 'scene-0443', 'scene-0444', 'scene-0445', 'scene-0447', 'scene-0448', 'scene-0450', 'scene-0451', 'scene-0454', 'scene-0455', 'scene-0456', 'scene-0458', 'scene-0459', 'scene-0461', 'scene-0462', 'scene-0463', 'scene-0464', 'scene-0465', 'scene-0467', 'scene-0468', 'scene-0469', 'scene-0471', 'scene-0472', 'scene-0474', 'scene-0475', 'scene-0476', 'scene-0477', 'scene-0478', 'scene-0480', 'scene-0500', 'scene-0501', 'scene-0505', 'scene-0506', 'scene-0507', 'scene-0508', 'scene-0510', 'scene-0511', 'scene-0512', 'scene-0513', 'scene-0514', 'scene-0515', 'scene-0517', 'scene-0518', 'scene-0519', 'scene-0520', 'scene-0522', 'scene-0523', 'scene-0552', 'scene-0553', 'scene-0554', 'scene-0555', 'scene-0560', 'scene-0562', 'scene-0563', 'scene-0564', 'scene-0565', 'scene-0586', 'scene-0587', 'scene-0588', 'scene-0589', 'scene-0590', 'scene-0591', 'scene-0592', 'scene-0593', 'scene-0595', 'scene-0596', 'scene-0597', 'scene-0598', 'scene-0599', 'scene-0600', 'scene-0625', 'scene-0630', 'scene-0632', 'scene-0633', 'scene-0636', 'scene-0637', 'scene-0638', 'scene-0639', 'scene-0640', 'scene-0652', 'scene-0654', 'scene-0657', 'scene-0658', 'scene-0660', 'scene-0663', 'scene-0664', 'scene-0665', 'scene-0666', 'scene-0667', 'scene-0669', 'scene-0670', 'scene-0671', 'scene-0672', 'scene-0673', 'scene-0674', 'scene-0675', 'scene-0676', 'scene-0677', 'scene-0678', 'scene-0681', 'scene-0683', 'scene-0684', 'scene-0685', 'scene-0686', 'scene-0687', 'scene-0688', 'scene-0689', 'scene-0696', 'scene-0697', 'scene-0698', 'scene-0700', 'scene-0701', 'scene-0703', 'scene-0704', 'scene-0707', 'scene-0708', 'scene-0709', 'scene-0710', 'scene-0711', 'scene-0713', 'scene-0714', 'scene-0715', 'scene-0716', 'scene-0717', 'scene-0718', 'scene-0719', 'scene-0726', 'scene-0727', 'scene-0728', 'scene-0730', 'scene-0731', 'scene-0733', 'scene-0734', 'scene-0735', 'scene-0737', 'scene-0738', 'scene-0780', 'scene-0782', 'scene-0783', 'scene-0787', 'scene-0789', 'scene-0790', 'scene-0791', 'scene-0802', 'scene-0809', 'scene-0810', 'scene-0811', 'scene-0812', 'scene-0815', 'scene-0817', 'scene-0822', 'scene-0848', 'scene-0849', 'scene-0850', 'scene-0851', 'scene-0852', 'scene-0853', 'scene-0854', 'scene-0855', 'scene-0856', 'scene-0858', 'scene-0860', 'scene-0862', 'scene-0863', 'scene-0864', 'scene-0865', 'scene-0866', 'scene-0868', 'scene-0869', 'scene-0870', 'scene-0871', 'scene-0873', 'scene-0875', 'scene-0876', 'scene-0878', 'scene-0882', 'scene-0883', 'scene-0884', 'scene-0885', 'scene-0887', 'scene-0888', 'scene-0889', 'scene-0890', 'scene-0891', 'scene-0892', 'scene-0893', 'scene-0894', 'scene-0895', 'scene-0896', 'scene-0897', 'scene-0898', 'scene-0899', 'scene-0900', 'scene-0901', 'scene-0902', 'scene-0904', 'scene-0905', 'scene-0906', 'scene-0907', 'scene-0908', 'scene-0909', 'scene-0916', 'scene-0917', 'scene-0925', 'scene-0927', 'scene-0928', 'scene-0929', 'scene-0931', 'scene-0945', 'scene-0947', 'scene-0949', 'scene-0952', 'scene-0953', 'scene-0955', 'scene-0956', 'scene-0957', 'scene-0958', 'scene-0959', 'scene-0960', 'scene-0966', 'scene-0967', 'scene-0968', 'scene-0969', 'scene-0971', 'scene-0972', 'scene-0975', 'scene-0976', 'scene-0978', 'scene-0979', 'scene-0981', 'scene-0982', 'scene-0983', 'scene-0984', 'scene-0988', 'scene-0989', 'scene-0990', 'scene-0994', 'scene-0995', 'scene-0997', 'scene-0999', 'scene-1000', 'scene-1001', 'scene-1004', 'scene-1005', 'scene-1007', 'scene-1008', 'scene-1009', 'scene-1010', 'scene-1011', 'scene-1012', 'scene-1013', 'scene-1014', 'scene-1015', 'scene-1019', 'scene-1021', 'scene-1022', 'scene-1023', 'scene-1024', 'scene-1046', 'scene-1047', 'scene-1049', 'scene-1050', 'scene-1051', 'scene-1053', 'scene-1064', 'scene-1065', 'scene-1066', 'scene-1068', 'scene-1069', 'scene-1070', 'scene-1073', 'scene-1074', 'scene-1075', 'scene-1076', 'scene-1078', 'scene-1080', 'scene-1081', 'scene-1082', 'scene-1083', 'scene-1086', 'scene-1087', 'scene-1089', 'scene-1090', 'scene-1091', 'scene-1092', 'scene-1093', 'scene-1094', 'scene-1095', 'scene-1096', 'scene-1097', 'scene-1099', 'scene-1100', 'scene-1101', 'scene-1104', 'scene-1105', 'scene-1106', 'scene-1107', 'scene-1108', 'scene-1109', 'scene-1110']\n"
     ]
    }
   ],
   "source": [
    "train_new.sort()\n",
    "print(train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab930aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "082cdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看GT的类别编号\n",
    "import torch\n",
    "import numpy as np\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "475ed50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "label_path = '/home/gs/workspace/datasets/nuscenes_processed/map-labels-mini'\n",
    "lable_name = '0b2eb9c1cd1b45f0b1664a01684c5767.png'\n",
    "label_color_name = '0b2eb9c1cd1b45f0b1664a01684c5767_c.png'\n",
    "label = torch.from_numpy(io.imread(label_path + '/' + lable_name)).long()\n",
    "label_color = io.imread(label_path + '/' + label_color_name)\n",
    "print(label_color.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "288ccc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f207226",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0 = torch.where(label==0, 255, 0).numpy()\n",
    "label_0 = np.expand_dims(label_0, 2).repeat(3, axis=2)\n",
    "\n",
    "label_1 = torch.where(label==1, 255, 0).numpy()\n",
    "label_1 = np.expand_dims(label_1, 2).repeat(3, axis=2)\n",
    "\n",
    "label_2 = torch.where(label==2, 255, 0).numpy()\n",
    "label_2 = np.expand_dims(label_2, 2).repeat(3, axis=2)\n",
    "\n",
    "label_3 = torch.where(label==3, 255, 0).numpy()\n",
    "label_3 = np.expand_dims(label_3, 2).repeat(3, axis=2)\n",
    "\n",
    "label_4 = torch.where(label==4, 255, 0).numpy()\n",
    "label_4 = np.expand_dims(label_4, 2).repeat(3, axis=2)\n",
    "\n",
    "label_5 = torch.where(label==5, 255, 0).numpy()\n",
    "label_5 = np.expand_dims(label_5, 2).repeat(3, axis=2)\n",
    "\n",
    "label_6 = torch.where(label==6, 255, 0).numpy()\n",
    "label_6 = np.expand_dims(label_6, 2).repeat(3, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b4b66236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "print(type(label_0))\n",
    "print(label_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3ce46863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(2,4,1)\n",
    "plt.imshow(label_0)\n",
    "plt.title('label_0')\n",
    "\n",
    "plt.subplot(2,4,2)\n",
    "plt.imshow(label_1)\n",
    "plt.title('label_1')\n",
    "\n",
    "plt.subplot(2,4,3)\n",
    "plt.imshow(label_2)\n",
    "plt.title('label_2')\n",
    "\n",
    "plt.subplot(2,4,4)\n",
    "plt.imshow(label_3)\n",
    "plt.title('label_3')\n",
    "\n",
    "plt.subplot(2,4,5)\n",
    "plt.imshow(label_4)\n",
    "plt.title('label_4')\n",
    "\n",
    "plt.subplot(2,4,6)\n",
    "plt.imshow(label_5)\n",
    "plt.title('label_5')\n",
    "\n",
    "plt.subplot(2,4,7)\n",
    "plt.imshow(label_6)\n",
    "plt.title('label_6')\n",
    "\n",
    "plt.subplot(2,4,8)\n",
    "plt.imshow(label_color)\n",
    "plt.title('label_color')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e7a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c985a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a07860ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型\n",
    "from torch import nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "731b5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'resnet101'\n",
    "pretrain = 'imagenet'\n",
    "base_model = getattr(torchvision.models, base_model)(True if pretrain == 'imagenet' else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "213341b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f114ce55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "new_model = torch.nn.Sequential(*(list(base_model.children())[:-2]))\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "afe286fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048, 15, 25])\n"
     ]
    }
   ],
   "source": [
    "input_test = torch.randn(1, 3, 450, 800) # (N, C, H, W)\n",
    "output = new_model(input_test)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "92c0ea4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 800, 9)\n"
     ]
    }
   ],
   "source": [
    "# input img in a list and then concatenate\n",
    "input_1 = torch.randn(450, 800, 3)\n",
    "input_2 = torch.randn(450, 800, 3)\n",
    "input_3 = torch.randn(450, 800, 3)\n",
    "img_group = [input_1, input_2, input_3]\n",
    "#input_con = np.concatenate([np.array(x)[:, :, ::-1] for x in img_group], axis=2)\n",
    "input_con = np.concatenate(img_group, axis=2)\n",
    "print(input_con.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "82704403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 450, 800])\n"
     ]
    }
   ],
   "source": [
    "class ToTorchFormatTensor(object):\n",
    "    \"\"\" Converts a PIL.Image (RGB) or numpy.ndarray (H x W x C) in the range [0, 255]\n",
    "    to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] \"\"\"\n",
    "    def __init__(self, div=True):\n",
    "        self.div = div\n",
    "\n",
    "    def __call__(self, pic):\n",
    "        if isinstance(pic, np.ndarray):\n",
    "            # handle numpy array\n",
    "            img = torch.from_numpy(pic).permute(2, 0, 1).contiguous()\n",
    "        else:\n",
    "            # handle PIL Image\n",
    "            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
    "            img = img.view(pic.size[1], pic.size[0], len(pic.mode))\n",
    "            # put it from HWC to CHW format\n",
    "            # yikes, this transpose takes 80% of the loading time/CPU\n",
    "            img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "        return img.float().div(255) if self.div else img.float()\n",
    "\n",
    "ToTensor = ToTorchFormatTensor\n",
    "input_tensor = ToTensor()(input_con)\n",
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d29fe9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 450, 800])\n"
     ]
    }
   ],
   "source": [
    "input_new = torch.randn(1, 9, 450, 800)\n",
    "sample_len = 3\n",
    "input_view = input_new.view((-1, sample_len) + input_new.size()[-2:])\n",
    "print(input_view.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2aad48a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "base_model.last_layer_name = 'fc'\n",
    "#base_model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "base_model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "print(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "76a0e63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BasicBlock(\n",
       "   (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " BasicBlock(\n",
       "   (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " BasicBlock(\n",
       "   (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " )]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks = list(base_model.layer1.children())\n",
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4079abd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9cfb4a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 3]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_segment = 3\n",
    "n_segment_list = [n_segment] * 4\n",
    "n_segment_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset [conda env: dataset]",
   "language": "python",
   "name": "dataset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
